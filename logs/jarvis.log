2025-05-07T17:29:11.452080 | [95mCRITICAL[0m | [__main__:39] | Failed to initialize JARVIS: expected string or bytes-like object, got 'function'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 27, in __init__
    setup_logging(level="DEBUG" if "--debug" in sys.argv else "INFO")
  File "c:\nova_industrie\jarvis\core\logging\logger.py", line 69, in setup_logging
    logging.Formatter(lambda x: json.dumps({
  File "C:\Python312\Lib\logging\__init__.py", line 614, in __init__
    self._style.validate()
  File "C:\Python312\Lib\logging\__init__.py", line 452, in validate
    if not self.validation_pattern.search(self._fmt):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: expected string or bytes-like object, got 'function'
2025-05-07T17:30:11.236326 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\database.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:30:11.237329 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\llm.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:30:11.237846 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ml.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:30:11.237846 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ui.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:30:11.241818 | [92mINFO[0m | [__main__:46] | Configuration system initialized
2025-05-07T17:30:11.241818 | [91mERROR[0m | [__main__:59] | Core components initialization failed
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:30:11.243018 | [95mCRITICAL[0m | [__main__:39] | Failed to initialize JARVIS: LLMCore.__init__() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 31, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:32:14.834260 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\database.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:32:14.834767 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\llm.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:32:14.835273 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ml.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:32:14.835273 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ui.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:32:14.838975 | [92mINFO[0m | [__main__:46] | Configuration system initialized
2025-05-07T17:32:14.838975 | [91mERROR[0m | [__main__:59] | Core components initialization failed
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:32:14.839479 | [95mCRITICAL[0m | [__main__:39] | Failed to initialize JARVIS: LLMCore.__init__() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 31, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:35:11.602200 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\database.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:35:11.603742 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\llm.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:35:11.603742 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ml.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:35:11.604428 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ui.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:35:11.608017 | [92mINFO[0m | [__main__:46] | Configuration system initialized
2025-05-07T17:35:11.608017 | [91mERROR[0m | [__main__:59] | Core components initialization failed
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:35:11.608524 | [95mCRITICAL[0m | [__main__:39] | Failed to initialize JARVIS: LLMCore.__init__() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 31, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:36:21.253120 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\database.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:36:21.253640 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\llm.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:36:21.254144 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ml.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:36:21.254651 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ui.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:36:21.258804 | [92mINFO[0m | [__main__:46] | Configuration system initialized
2025-05-07T17:36:21.259304 | [91mERROR[0m | [__main__:59] | Core components initialization failed
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:36:21.259804 | [95mCRITICAL[0m | [__main__:39] | Failed to initialize JARVIS: LLMCore.__init__() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 31, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:37:29.884019 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\database.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:37:29.884937 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\llm.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:37:29.885436 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ml.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:37:29.885436 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ui.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:37:29.889497 | [92mINFO[0m | [__main__:46] | Configuration system initialized
2025-05-07T17:37:29.889497 | [91mERROR[0m | [__main__:59] | Core components initialization failed
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:37:29.890006 | [95mCRITICAL[0m | [__main__:39] | Failed to initialize JARVIS: LLMCore.__init__() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 31, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 55, in _init_core_components
    self.llm = LLMCore(config=self.config_manager.get('llm'))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: LLMCore.__init__() got an unexpected keyword argument 'config'
2025-05-07T17:44:56.188278 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\database.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:44:56.189281 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\llm.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:44:56.189793 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ml.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:44:56.190296 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ui.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:44:56.195188 | [92mINFO[0m | [__main__:48] | Configuration system initialized
2025-05-07T17:44:56.195188 | [93mWARNING[0m | [__main__:61] | No LLM config found, using defaults
2025-05-07T17:44:56.195948 | [91mERROR[0m | [llm.core.llm_core:36] | Failed to initialize LLMCore: DatabaseManager.__init__() takes 1 positional argument but 2 were given
2025-05-07T17:44:56.196448 | [91mERROR[0m | [__main__:75] | Core components initialization failed
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 70, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 29, in __init__
    self.db = DatabaseManager(db_config)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: DatabaseManager.__init__() takes 1 positional argument but 2 were given
2025-05-07T17:44:56.197988 | [95mCRITICAL[0m | [__main__:41] | Failed to initialize JARVIS: DatabaseManager.__init__() takes 1 positional argument but 2 were given
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 33, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 70, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 29, in __init__
    self.db = DatabaseManager(db_config)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: DatabaseManager.__init__() takes 1 positional argument but 2 were given
2025-05-07T17:46:14.587053 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\llm.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:46:14.587554 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ml.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:46:14.588200 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ui.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:46:14.591264 | [92mINFO[0m | [__main__:48] | Configuration system initialized
2025-05-07T17:46:14.591264 | [93mWARNING[0m | [__main__:61] | No LLM config found, using defaults
2025-05-07T17:46:15.493731 | [91mERROR[0m | [llm.core.llm_core:76] | Model initialization failed: 'dict' object has no attribute 'attention_slicing'
2025-05-07T17:46:15.494231 | [91mERROR[0m | [llm.core.llm_core:36] | Failed to initialize LLMCore: 'dict' object has no attribute 'attention_slicing'
2025-05-07T17:46:15.494732 | [91mERROR[0m | [__main__:75] | Core components initialization failed
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 70, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 33, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 70, in _initialize_model
    self.model = self.optimizer.optimize_inference(self.model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\optimization\llm_optimizer.py", line 26, in optimize_inference
    if self.config.attention_slicing:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'attention_slicing'
2025-05-07T17:46:15.496732 | [95mCRITICAL[0m | [__main__:41] | Failed to initialize JARVIS: 'dict' object has no attribute 'attention_slicing'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 33, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 70, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 33, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 70, in _initialize_model
    self.model = self.optimizer.optimize_inference(self.model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\optimization\llm_optimizer.py", line 26, in optimize_inference
    if self.config.attention_slicing:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'attention_slicing'
2025-05-07T17:48:10.572214 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\llm.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:48:10.573550 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ml.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:48:10.573550 | [91mERROR[0m | [config.manager:44] | Failed to load config c:\nova_industrie\jarvis\config\defaults\ui.json: Expecting value: line 1 column 1 (char 0)
2025-05-07T17:48:10.578223 | [92mINFO[0m | [__main__:48] | Configuration system initialized
2025-05-07T17:48:10.578748 | [93mWARNING[0m | [__main__:61] | No LLM config found, using defaults
2025-05-07T17:48:11.474745 | [91mERROR[0m | [llm.core.llm_core:76] | Model initialization failed: 'dict' object has no attribute 'attention_slicing'
2025-05-07T17:48:11.474745 | [91mERROR[0m | [llm.core.llm_core:36] | Failed to initialize LLMCore: 'dict' object has no attribute 'attention_slicing'
2025-05-07T17:48:11.475277 | [91mERROR[0m | [__main__:75] | Core components initialization failed
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 70, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 33, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 70, in _initialize_model
    self.model = self.optimizer.optimize_inference(self.model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\optimization\llm_optimizer.py", line 26, in optimize_inference
    if self.config.attention_slicing:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'attention_slicing'
2025-05-07T17:48:11.476276 | [95mCRITICAL[0m | [__main__:41] | Failed to initialize JARVIS: 'dict' object has no attribute 'attention_slicing'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 33, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 70, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 33, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 70, in _initialize_model
    self.model = self.optimizer.optimize_inference(self.model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\optimization\llm_optimizer.py", line 26, in optimize_inference
    if self.config.attention_slicing:
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'attention_slicing'
2025-05-07 16:27:08,121 | [95mCRITICAL[0m | [__main__:59] | Failed to initialize JARVIS: 'JARVIS' object has no attribute '_init_config'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 50, in __init__
    self._init_config()
    ^^^^^^^^^^^^^^^^^
AttributeError: 'JARVIS' object has no attribute '_init_config'. Did you mean: '_load_config'?
2025-05-07 16:28:16,618 | [91mERROR[0m | [__main__:87] | Failed to initialize config system
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 72, in _load_config
    self.logger.warning("Config file not found, using defaults")
    ^^^^^^^^^^^
AttributeError: 'JARVIS' object has no attribute 'logger'
2025-05-07 16:28:16,619 | [95mCRITICAL[0m | [__main__:61] | Failed to initialize JARVIS: 'JARVIS' object has no attribute 'logger'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 52, in __init__
    self.config = self._load_config()  # Use existing _load_config instead of _init_config
                  ^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/main.py", line 72, in _load_config
    self.logger.warning("Config file not found, using defaults")
    ^^^^^^^^^^^
AttributeError: 'JARVIS' object has no attribute 'logger'
2025-05-07 16:29:59,233 | [91mERROR[0m | [config.config_validator:32] | Config validation failed: 'language' is a required property

Failed validating 'required' in schema:
    {'type': 'object',
     'properties': {'language': {'type': 'string', 'enum': ['en', 'nl']},
                    'models': {'type': 'object',
                               'properties': {'sentiment': {'type': 'string'},
                                              'intent': {'type': 'string'},
                                              'embedding': {'type': 'string'}}},
                    'tokenizer': {'type': 'object',
                                  'properties': {'max_length': {'type': 'integer'},
                                                 'padding': {'type': 'boolean'}}}},
     'required': ['language']}

On instance:
    {'model': 'gpt2', 'max_length': 100}
2025-05-07 16:29:59,234 | [93mWARNING[0m | [__main__:116] | Invalid nlp config, using defaults
2025-05-07 16:29:59,237 | [91mERROR[0m | [config.config_validator:32] | Config validation failed: {'name': 'gpt2', 'max_length': 100} is not of type 'string'

Failed validating 'type' in schema['properties']['model']:
    {'type': 'string'}

On instance['model']:
    {'name': 'gpt2', 'max_length': 100}
2025-05-07 16:29:59,237 | [93mWARNING[0m | [__main__:116] | Invalid llm config, using defaults
2025-05-07 16:29:59,237 | [91mERROR[0m | [config.config_validator:26] | Schema ui not found
2025-05-07 16:29:59,237 | [93mWARNING[0m | [__main__:116] | Invalid ui config, using defaults
2025-05-07 16:29:59,238 | [92mINFO[0m | [Cerebrum:22] | Cerebrum initialized successfully
2025-05-07 16:29:59,238 | [91mERROR[0m | [llm.core.llm_core:34] | Failed to initialize LLMCore: DatabaseManager.__init__() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/llm/core/llm_core.py", line 26, in __init__
    self.db = DatabaseManager(config=self.config.get("database", {}))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: DatabaseManager.__init__() got an unexpected keyword argument 'config'
2025-05-07 16:29:59,238 | [91mERROR[0m | [__main__:135] | Core components initialization failed: DatabaseManager.__init__() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 130, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/core/llm_core.py", line 26, in __init__
    self.db = DatabaseManager(config=self.config.get("database", {}))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: DatabaseManager.__init__() got an unexpected keyword argument 'config'
2025-05-07 16:29:59,239 | [95mCRITICAL[0m | [__main__:64] | Failed to initialize JARVIS: DatabaseManager.__init__() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 56, in __init__
    self._init_core_components()
  File "/workspaces/J.A.R.V.I.S/main.py", line 130, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/core/llm_core.py", line 26, in __init__
    self.db = DatabaseManager(config=self.config.get("database", {}))
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: DatabaseManager.__init__() got an unexpected keyword argument 'config'
2025-05-07 16:31:24,267 | [91mERROR[0m | [config.config_validator:32] | Config validation failed: {'name': 'gpt2', 'max_length': 100} is not of type 'string'

Failed validating 'type' in schema['properties']['model']:
    {'type': 'string'}

On instance['model']:
    {'name': 'gpt2', 'max_length': 100}
2025-05-07 16:31:24,268 | [93mWARNING[0m | [__main__:128] | Invalid llm config, using defaults
2025-05-07 16:31:24,268 | [91mERROR[0m | [config.config_validator:26] | Schema ui not found
2025-05-07 16:31:24,268 | [93mWARNING[0m | [__main__:128] | Invalid ui config, using defaults
2025-05-07 16:31:24,268 | [92mINFO[0m | [Cerebrum:22] | Cerebrum initialized successfully
2025-05-07 16:31:24,280 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 16:31:24,280 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: gpt2
2025-05-07 16:31:25,283 | [92mINFO[0m | [llm.optimization.llm_optimizer:53] | Model optimization completed successfully
2025-05-07 16:31:25,283 | [92mINFO[0m | [llm.core.llm_core:31] | LLMCore initialized successfully
2025-05-07 16:31:25,285 | [91mERROR[0m | [__main__:147] | Core components initialization failed: 'Cerebrum' object has no attribute 'initialize'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 143, in _init_core_components
    self.brain.initialize()
    ^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Cerebrum' object has no attribute 'initialize'. Did you mean: 'initialized'?
2025-05-07 16:31:25,290 | [95mCRITICAL[0m | [__main__:65] | Failed to initialize JARVIS: 'Cerebrum' object has no attribute 'initialize'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 57, in __init__
    self._init_core_components()
  File "/workspaces/J.A.R.V.I.S/main.py", line 143, in _init_core_components
    self.brain.initialize()
    ^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Cerebrum' object has no attribute 'initialize'. Did you mean: 'initialized'?
2025-05-07 16:33:41,210 | [91mERROR[0m | [config.config_validator:32] | Config validation failed: {'name': 'gpt2', 'max_length': 100} is not of type 'string'

Failed validating 'type' in schema['properties']['model']:
    {'type': 'string'}

On instance['model']:
    {'name': 'gpt2', 'max_length': 100}
2025-05-07 16:33:41,210 | [93mWARNING[0m | [__main__:128] | Invalid llm config, using defaults
2025-05-07 16:33:41,211 | [91mERROR[0m | [config.config_validator:26] | Schema ui not found
2025-05-07 16:33:41,211 | [93mWARNING[0m | [__main__:128] | Invalid ui config, using defaults
2025-05-07 16:33:41,211 | [91mERROR[0m | [__main__:162] | System initialization failed: KnowledgeManager.__init__() missing 1 required positional argument: 'db'
2025-05-07 16:33:41,211 | [91mERROR[0m | [__main__:152] | Core components initialization failed: KnowledgeManager.__init__() missing 1 required positional argument: 'db'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 142, in _init_core_components
    self._init_systems()  # Initialize core systems
    ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/main.py", line 158, in _init_systems
    self.knowledge_manager = KnowledgeManager()
                             ^^^^^^^^^^^^^^^^^^
TypeError: KnowledgeManager.__init__() missing 1 required positional argument: 'db'
2025-05-07 16:33:41,212 | [95mCRITICAL[0m | [__main__:65] | Failed to initialize JARVIS: KnowledgeManager.__init__() missing 1 required positional argument: 'db'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 57, in __init__
    self._init_core_components()
  File "/workspaces/J.A.R.V.I.S/main.py", line 142, in _init_core_components
    self._init_systems()  # Initialize core systems
    ^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/main.py", line 158, in _init_systems
    self.knowledge_manager = KnowledgeManager()
                             ^^^^^^^^^^^^^^^^^^
TypeError: KnowledgeManager.__init__() missing 1 required positional argument: 'db'
2025-05-07 16:35:22,912 | [91mERROR[0m | [config.config_validator:32] | Config validation failed: {'name': 'gpt2', 'max_length': 100} is not of type 'string'

Failed validating 'type' in schema['properties']['model']:
    {'type': 'string'}

On instance['model']:
    {'name': 'gpt2', 'max_length': 100}
2025-05-07 16:35:22,912 | [93mWARNING[0m | [__main__:129] | Invalid llm config, using defaults
2025-05-07 16:35:22,912 | [91mERROR[0m | [config.config_validator:26] | Schema ui not found
2025-05-07 16:35:22,912 | [93mWARNING[0m | [__main__:129] | Invalid ui config, using defaults
2025-05-07 16:35:22,917 | [91mERROR[0m | [__main__:168] | System initialization failed: StructuredLearningPipeline.__init__() missing 2 required positional arguments: 'config' and 'knowledge_manager'
2025-05-07 16:35:22,917 | [91mERROR[0m | [__main__:152] | Core components initialization failed: StructuredLearningPipeline.__init__() missing 2 required positional arguments: 'config' and 'knowledge_manager'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 143, in _init_core_components
    self._init_systems()
  File "/workspaces/J.A.R.V.I.S/main.py", line 163, in _init_systems
    self.learning_manager = LearningManager(self.config.get('learning', {}))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/learning_manager.py", line 30, in __init__
    self.structured_pipeline = StructuredLearningPipeline()
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: StructuredLearningPipeline.__init__() missing 2 required positional arguments: 'config' and 'knowledge_manager'
2025-05-07 16:35:22,918 | [95mCRITICAL[0m | [__main__:66] | Failed to initialize JARVIS: StructuredLearningPipeline.__init__() missing 2 required positional arguments: 'config' and 'knowledge_manager'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 58, in __init__
    self._init_core_components()
  File "/workspaces/J.A.R.V.I.S/main.py", line 143, in _init_core_components
    self._init_systems()
  File "/workspaces/J.A.R.V.I.S/main.py", line 163, in _init_systems
    self.learning_manager = LearningManager(self.config.get('learning', {}))
                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/learning_manager.py", line 30, in __init__
    self.structured_pipeline = StructuredLearningPipeline()
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: StructuredLearningPipeline.__init__() missing 2 required positional arguments: 'config' and 'knowledge_manager'
2025-05-07 16:46:55,774 | [91mERROR[0m | [config.config_validator:32] | Config validation failed: {'name': 'gpt2', 'max_length': 100} is not of type 'string'

Failed validating 'type' in schema['properties']['model']:
    {'type': 'string'}

On instance['model']:
    {'name': 'gpt2', 'max_length': 100}
2025-05-07 16:46:55,775 | [93mWARNING[0m | [__main__:129] | Invalid llm config, using defaults
2025-05-07 16:46:55,775 | [91mERROR[0m | [config.config_validator:26] | Schema ui not found
2025-05-07 16:46:55,775 | [93mWARNING[0m | [__main__:129] | Invalid ui config, using defaults
2025-05-07 16:46:55,778 | [91mERROR[0m | [__main__:176] | System initialization failed: 'dict' object has no attribute 'to'
2025-05-07 16:46:55,778 | [91mERROR[0m | [__main__:152] | Core components initialization failed: 'dict' object has no attribute 'to'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 143, in _init_core_components
    self._init_systems()
  File "/workspaces/J.A.R.V.I.S/main.py", line 166, in _init_systems
    self.learning_manager = LearningManager(
                            ^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/learning_manager.py", line 34, in __init__
    self.structured_pipeline = StructuredLearningPipeline(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/pipelines/structured_learning.py", line 19, in __init__
    self.trainer = ModelTrainer(config.get('training_config', {}))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/ml/training/trainers/model_trainer.py", line 16, in __init__
    self._set_model(model)
  File "/workspaces/J.A.R.V.I.S/ml/training/trainers/model_trainer.py", line 22, in _set_model
    self.model.to(self.device)
    ^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'to'
2025-05-07 16:46:55,780 | [95mCRITICAL[0m | [__main__:66] | Failed to initialize JARVIS: 'dict' object has no attribute 'to'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 58, in __init__
    self._init_core_components()
  File "/workspaces/J.A.R.V.I.S/main.py", line 143, in _init_core_components
    self._init_systems()
  File "/workspaces/J.A.R.V.I.S/main.py", line 166, in _init_systems
    self.learning_manager = LearningManager(
                            ^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/learning_manager.py", line 34, in __init__
    self.structured_pipeline = StructuredLearningPipeline(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/pipelines/structured_learning.py", line 19, in __init__
    self.trainer = ModelTrainer(config.get('training_config', {}))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/ml/training/trainers/model_trainer.py", line 16, in __init__
    self._set_model(model)
  File "/workspaces/J.A.R.V.I.S/ml/training/trainers/model_trainer.py", line 22, in _set_model
    self.model.to(self.device)
    ^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'to'
2025-05-07 16:49:10,742 | [91mERROR[0m | [config.config_validator:32] | Config validation failed: {'name': 'gpt2', 'max_length': 100} is not of type 'string'

Failed validating 'type' in schema['properties']['model']:
    {'type': 'string'}

On instance['model']:
    {'name': 'gpt2', 'max_length': 100}
2025-05-07 16:49:10,742 | [93mWARNING[0m | [__main__:129] | Invalid llm config, using defaults
2025-05-07 16:49:10,742 | [91mERROR[0m | [config.config_validator:26] | Schema ui not found
2025-05-07 16:49:10,742 | [93mWARNING[0m | [__main__:129] | Invalid ui config, using defaults
2025-05-07 16:49:10,745 | [91mERROR[0m | [__main__:176] | System initialization failed: 'dict' object has no attribute 'to'
2025-05-07 16:49:10,745 | [91mERROR[0m | [__main__:152] | Core components initialization failed: 'dict' object has no attribute 'to'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 143, in _init_core_components
    self._init_systems()
  File "/workspaces/J.A.R.V.I.S/main.py", line 166, in _init_systems
    self.learning_manager = LearningManager(
                            ^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/learning_manager.py", line 34, in __init__
    self.structured_pipeline = StructuredLearningPipeline(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/pipelines/structured_learning.py", line 19, in __init__
    self.trainer = ModelTrainer(config.get('training_config', {}))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/ml/training/trainers/model_trainer.py", line 16, in __init__
    self._set_model(model)
  File "/workspaces/J.A.R.V.I.S/ml/training/trainers/model_trainer.py", line 22, in _set_model
    self.model.to(self.device)
    ^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'to'
2025-05-07 16:49:10,747 | [95mCRITICAL[0m | [__main__:66] | Failed to initialize JARVIS: 'dict' object has no attribute 'to'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 58, in __init__
    self._init_core_components()
  File "/workspaces/J.A.R.V.I.S/main.py", line 143, in _init_core_components
    self._init_systems()
  File "/workspaces/J.A.R.V.I.S/main.py", line 166, in _init_systems
    self.learning_manager = LearningManager(
                            ^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/learning_manager.py", line 34, in __init__
    self.structured_pipeline = StructuredLearningPipeline(
                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/llm/learning/pipelines/structured_learning.py", line 19, in __init__
    self.trainer = ModelTrainer(config.get('training_config', {}))
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/ml/training/trainers/model_trainer.py", line 16, in __init__
    self._set_model(model)
  File "/workspaces/J.A.R.V.I.S/ml/training/trainers/model_trainer.py", line 22, in _set_model
    self.model.to(self.device)
    ^^^^^^^^^^^^^
AttributeError: 'dict' object has no attribute 'to'
2025-05-07 17:14:48,911 | [91mERROR[0m | [config.config_validator:32] | Config validation failed: {'name': 'gpt2', 'max_length': 100} is not of type 'string'

Failed validating 'type' in schema['properties']['model']:
    {'type': 'string'}

On instance['model']:
    {'name': 'gpt2', 'max_length': 100}
2025-05-07 17:14:48,912 | [93mWARNING[0m | [__main__:129] | Invalid llm config, using defaults
2025-05-07 17:14:48,912 | [91mERROR[0m | [config.config_validator:26] | Schema ui not found
2025-05-07 17:14:48,912 | [93mWARNING[0m | [__main__:129] | Invalid ui config, using defaults
2025-05-07 17:14:48,915 | [92mINFO[0m | [__main__:174] | System components initialized
2025-05-07 17:14:48,916 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 17:14:48,916 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: gpt2
2025-05-07 17:14:50,040 | [92mINFO[0m | [llm.optimization.llm_optimizer:53] | Model optimization completed successfully
2025-05-07 17:14:50,041 | [92mINFO[0m | [llm.core.llm_core:31] | LLMCore initialized successfully
2025-05-07 17:14:50,041 | [92mINFO[0m | [__main__:149] | Core components initialized
2025-05-07 17:14:50,041 | [92mINFO[0m | [__main__:182] | ML components initialized
2025-05-07 17:14:50,669 | [92mINFO[0m | [OpenGL.platform.ctypesloader:70] | Failed to load library ( 'libGLX.so.0' ): libGLX.so.0: cannot open shared object file: No such file or directory
2025-05-07 17:14:50,671 | [92mINFO[0m | [OpenGL.platform.ctypesloader:70] | Failed to load library ( 'libOpenGL.so.0' ): libOpenGL.so.0: cannot open shared object file: No such file or directory
2025-05-07 17:14:50,673 | [92mINFO[0m | [OpenGL.platform.ctypesloader:70] | Failed to load library ( 'libGL.so.0' ): libGL.so.0: cannot open shared object file: No such file or directory
2025-05-07 17:14:50,674 | [92mINFO[0m | [OpenGL.acceleratesupport:24] | No OpenGL_accelerate module loaded: No module named 'OpenGL_accelerate'
2025-05-07 17:14:50,697 | [92mINFO[0m | [OpenGL.platform.ctypesloader:70] | Failed to load library ( 'libOpenGL.so.0' ): libOpenGL.so.0: cannot open shared object file: No such file or directory
2025-05-07 17:14:50,698 | [92mINFO[0m | [OpenGL.platform.ctypesloader:70] | Failed to load library ( 'libGL.so.0' ): libGL.so.0: cannot open shared object file: No such file or directory
2025-05-07 17:14:50,698 | [93mWARNING[0m | [ui.rendering.renderer_factory:19] | OpenGL not available
2025-05-07 17:14:50,699 | [91mERROR[0m | [security.auth.auth_service:36] | Failed to setup auth database: 'Database' object is not callable
2025-05-07 17:14:50,699 | [92mINFO[0m | [security.auth.auth_service:20] | AuthService initialized
2025-05-07 17:14:50,699 | [91mERROR[0m | [__main__:198] | UI initialization failed: Can't instantiate abstract class ChatScreen without an implementation for abstract methods 'handle_input', 'init'
2025-05-07 17:14:50,699 | [95mCRITICAL[0m | [__main__:66] | Failed to initialize JARVIS: Can't instantiate abstract class ChatScreen without an implementation for abstract methods 'handle_input', 'init'
Traceback (most recent call last):
  File "/workspaces/J.A.R.V.I.S/main.py", line 60, in __init__
    self._init_ui()
  File "/workspaces/J.A.R.V.I.S/main.py", line 191, in _init_ui
    success = self.screen.init()
              ^^^^^^^^^^^^^^^^^^
  File "/workspaces/J.A.R.V.I.S/ui/screen.py", line 87, in init
    self._init_screens()
  File "/workspaces/J.A.R.V.I.S/ui/screen.py", line 116, in _init_screens
    self.register_screen("chat", ChatScreen(self.llm_pipeline))
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Can't instantiate abstract class ChatScreen without an implementation for abstract methods 'handle_input', 'init'
2025-05-07 20:58:33,292 | [95mCRITICAL[0m | [__main__:46] | Failed to initialize JARVIS: name 'ConfigValidator' is not defined
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 34, in __init__
    self.config_validator = ConfigValidator()
                            ^^^^^^^^^^^^^^^
NameError: name 'ConfigValidator' is not defined
2025-05-07 21:07:11,385 | [91mERROR[0m | [__main__:116] | Failed to initialize config system: ConfigValidator.validate() takes 2 positional arguments but 3 were given
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 109, in _load_config
    if not self.config_validator.validate(config.get(section, {}), section):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ConfigValidator.validate() takes 2 positional arguments but 3 were given
2025-05-07 21:07:11,385 | [91mERROR[0m | [__main__:157] | System initialization failed: name 'DatabaseManager' is not defined
2025-05-07 21:07:11,385 | [91mERROR[0m | [__main__:133] | Core components initialization failed: name 'DatabaseManager' is not defined
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 124, in _init_core_components
    self._init_systems()
  File "c:\nova_industrie\jarvis\main.py", line 140, in _init_systems
    self.db_manager = DatabaseManager()
                      ^^^^^^^^^^^^^^^
NameError: name 'DatabaseManager' is not defined
2025-05-07 21:07:11,389 | [95mCRITICAL[0m | [__main__:47] | Failed to initialize JARVIS: name 'DatabaseManager' is not defined
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 39, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 124, in _init_core_components
    self._init_systems()
  File "c:\nova_industrie\jarvis\main.py", line 140, in _init_systems
    self.db_manager = DatabaseManager()
                      ^^^^^^^^^^^^^^^
NameError: name 'DatabaseManager' is not defined
2025-05-07 21:09:50,716 | [91mERROR[0m | [__main__:124] | Failed to initialize config system: ConfigValidator.validate() takes 2 positional arguments but 3 were given
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 117, in _load_config
    if not self.config_validator.validate(config.get(section, {}), section):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ConfigValidator.validate() takes 2 positional arguments but 3 were given
2025-05-07 21:09:50,747 | [92mINFO[0m | [__main__:163] | System components initialized
2025-05-07 21:09:50,747 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 21:09:50,749 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: gpt2
2025-05-07 21:09:52,113 | [92mINFO[0m | [llm.optimization.llm_optimizer:53] | Model optimization completed successfully
2025-05-07 21:09:52,114 | [92mINFO[0m | [llm.core.llm_core:31] | LLMCore initialized successfully
2025-05-07 21:09:52,114 | [92mINFO[0m | [__main__:138] | Core components initialized
2025-05-07 21:09:52,114 | [92mINFO[0m | [__main__:171] | ML components initialized
2025-05-07 21:09:53,239 | [91mERROR[0m | [ui.rendering.opengl_renderer:46] | OpenGL initialization failed: No valid ImGui context. Use imgui.create_context() first and/or imgui.set_current_context().
2025-05-07 21:09:53,239 | [91mERROR[0m | [security.auth.auth_service:36] | Failed to setup auth database: 'Database' object is not callable
2025-05-07 21:09:53,239 | [92mINFO[0m | [security.auth.auth_service:20] | AuthService initialized
2025-05-07 21:09:53,240 | [91mERROR[0m | [__main__:187] | UI initialization failed: Can't instantiate abstract class ChatScreen without an implementation for abstract methods 'handle_input', 'init'
2025-05-07 21:09:53,240 | [95mCRITICAL[0m | [__main__:55] | Failed to initialize JARVIS: Can't instantiate abstract class ChatScreen without an implementation for abstract methods 'handle_input', 'init'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 49, in __init__
    self._init_ui()
  File "c:\nova_industrie\jarvis\main.py", line 180, in _init_ui
    success = self.screen.init()
              ^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\ui\screen.py", line 89, in init
    self._init_screens()
  File "c:\nova_industrie\jarvis\ui\screen.py", line 117, in _init_screens
    self.register_screen("chat", ChatScreen(self.llm_pipeline))
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: Can't instantiate abstract class ChatScreen without an implementation for abstract methods 'handle_input', 'init'
2025-05-07 21:11:05,640 | [93mWARNING[0m | [__main__:118] | Invalid llm config, using defaults
2025-05-07 21:11:05,645 | [92mINFO[0m | [__main__:163] | System components initialized
2025-05-07 21:11:05,645 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 21:11:05,647 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: gpt2
2025-05-07 21:11:06,531 | [92mINFO[0m | [llm.optimization.llm_optimizer:53] | Model optimization completed successfully
2025-05-07 21:11:06,531 | [92mINFO[0m | [llm.core.llm_core:31] | LLMCore initialized successfully
2025-05-07 21:11:06,531 | [92mINFO[0m | [__main__:138] | Core components initialized
2025-05-07 21:11:06,531 | [92mINFO[0m | [__main__:171] | ML components initialized
2025-05-07 21:11:07,709 | [91mERROR[0m | [security.auth.auth_service:36] | Failed to setup auth database: 'Database' object is not callable
2025-05-07 21:11:07,709 | [92mINFO[0m | [security.auth.auth_service:20] | AuthService initialized
2025-05-07 21:11:07,710 | [91mERROR[0m | [__main__:187] | UI initialization failed: Can't instantiate abstract class DataScreen without an implementation for abstract methods 'handle_input', 'init', 'render'
2025-05-07 21:11:07,710 | [95mCRITICAL[0m | [__main__:55] | Failed to initialize JARVIS: Can't instantiate abstract class DataScreen without an implementation for abstract methods 'handle_input', 'init', 'render'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 49, in __init__
    self._init_ui()
  File "c:\nova_industrie\jarvis\main.py", line 180, in _init_ui
    success = self.screen.init()
              ^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\ui\screen.py", line 87, in init
    self._init_screens()
  File "c:\nova_industrie\jarvis\ui\screen.py", line 122, in _init_screens
    self.register_screen("data", DataScreen())
                                 ^^^^^^^^^^^^
TypeError: Can't instantiate abstract class DataScreen without an implementation for abstract methods 'handle_input', 'init', 'render'
2025-05-07 21:12:18,248 | [93mWARNING[0m | [__main__:118] | Invalid llm config, using defaults
2025-05-07 21:12:18,253 | [92mINFO[0m | [__main__:163] | System components initialized
2025-05-07 21:12:18,253 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 21:12:18,254 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: gpt2
2025-05-07 21:12:18,965 | [92mINFO[0m | [llm.optimization.llm_optimizer:53] | Model optimization completed successfully
2025-05-07 21:12:18,966 | [92mINFO[0m | [llm.core.llm_core:31] | LLMCore initialized successfully
2025-05-07 21:12:18,966 | [92mINFO[0m | [__main__:138] | Core components initialized
2025-05-07 21:12:18,966 | [92mINFO[0m | [__main__:171] | ML components initialized
2025-05-07 21:12:20,021 | [91mERROR[0m | [security.auth.auth_service:36] | Failed to setup auth database: 'Database' object is not callable
2025-05-07 21:12:20,021 | [92mINFO[0m | [security.auth.auth_service:20] | AuthService initialized
2025-05-07 21:12:20,023 | [91mERROR[0m | [__main__:187] | UI initialization failed: Can't instantiate abstract class DataScreen without an implementation for abstract methods 'handle_input', 'init', 'render'
2025-05-07 21:12:20,023 | [95mCRITICAL[0m | [__main__:55] | Failed to initialize JARVIS: Can't instantiate abstract class DataScreen without an implementation for abstract methods 'handle_input', 'init', 'render'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 49, in __init__
    self._init_ui()
  File "c:\nova_industrie\jarvis\main.py", line 180, in _init_ui
    success = self.screen.init()
              ^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\ui\screen.py", line 87, in init
    self._init_screens()
  File "c:\nova_industrie\jarvis\ui\screen.py", line 122, in _init_screens
    self.register_screen("data", DataScreen())
                                 ^^^^^^^^^^^^
TypeError: Can't instantiate abstract class DataScreen without an implementation for abstract methods 'handle_input', 'init', 'render'
2025-05-07 21:13:33,554 | [93mWARNING[0m | [__main__:118] | Invalid llm config, using defaults
2025-05-07 21:13:33,559 | [92mINFO[0m | [__main__:163] | System components initialized
2025-05-07 21:13:33,559 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 21:13:33,560 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: gpt2
2025-05-07 21:13:34,432 | [92mINFO[0m | [llm.optimization.llm_optimizer:53] | Model optimization completed successfully
2025-05-07 21:13:34,433 | [92mINFO[0m | [llm.core.llm_core:31] | LLMCore initialized successfully
2025-05-07 21:13:34,433 | [92mINFO[0m | [__main__:138] | Core components initialized
2025-05-07 21:13:34,433 | [92mINFO[0m | [__main__:171] | ML components initialized
2025-05-07 21:13:35,517 | [91mERROR[0m | [security.auth.auth_service:36] | Failed to setup auth database: 'Database' object is not callable
2025-05-07 21:13:35,517 | [92mINFO[0m | [security.auth.auth_service:20] | AuthService initialized
2025-05-07 21:13:35,517 | [92mINFO[0m | [__main__:185] | UI initialized successfully
2025-05-07 21:13:35,517 | [92mINFO[0m | [__main__:52] | JARVIS initialization complete
2025-05-07 21:13:35,517 | [92mINFO[0m | [__main__:197] | Starting main loop...
2025-05-07 21:13:35,518 | [95mCRITICAL[0m | [__main__:214] | Fatal error in main loop: 'Screen' object has no attribute 'should_exit'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 198, in run
    while not self.screen.should_exit:
              ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Screen' object has no attribute 'should_exit'. Did you mean: 'should_quit'?
2025-05-07 21:13:35,519 | [92mINFO[0m | [__main__:220] | Starting cleanup...
2025-05-07 21:13:35,526 | [91mERROR[0m | [ui.screen:206] | Error destroying ImGui context: Context invalid (None or destroyed)
2025-05-07 21:14:40,144 | [93mWARNING[0m | [__main__:118] | Invalid llm config, using defaults
2025-05-07 21:14:40,149 | [92mINFO[0m | [__main__:163] | System components initialized
2025-05-07 21:14:40,149 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 21:14:40,149 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: gpt2
2025-05-07 21:14:40,882 | [92mINFO[0m | [llm.optimization.llm_optimizer:53] | Model optimization completed successfully
2025-05-07 21:14:40,882 | [92mINFO[0m | [llm.core.llm_core:31] | LLMCore initialized successfully
2025-05-07 21:14:40,883 | [92mINFO[0m | [__main__:138] | Core components initialized
2025-05-07 21:14:40,883 | [92mINFO[0m | [__main__:171] | ML components initialized
2025-05-07 21:14:42,020 | [91mERROR[0m | [security.auth.auth_service:36] | Failed to setup auth database: 'Database' object is not callable
2025-05-07 21:14:42,020 | [92mINFO[0m | [security.auth.auth_service:20] | AuthService initialized
2025-05-07 21:14:42,020 | [92mINFO[0m | [__main__:185] | UI initialized successfully
2025-05-07 21:14:42,020 | [92mINFO[0m | [__main__:52] | JARVIS initialization complete
2025-05-07 21:14:42,021 | [92mINFO[0m | [__main__:197] | Starting main loop...
2025-05-07 21:14:42,021 | [95mCRITICAL[0m | [__main__:214] | Fatal error in main loop: 'Screen' object has no attribute 'should_exit'
Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 198, in run
    while not self.screen.should_exit:
              ^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Screen' object has no attribute 'should_exit'. Did you mean: 'should_quit'?
2025-05-07 21:14:42,023 | [92mINFO[0m | [__main__:220] | Starting cleanup...
2025-05-07 21:14:42,042 | [91mERROR[0m | [ui.screen:206] | Error destroying ImGui context: Context invalid (None or destroyed)
2025-05-07 21:16:24,303 | [93mWARNING[0m | [__main__:120] | Invalid llm config, using defaults
2025-05-07 21:16:24,309 | [92mINFO[0m | [__main__:165] | System components initialized
2025-05-07 21:16:24,309 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 21:16:24,309 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: jarvis-llm
2025-05-07 21:16:24,520 | [91mERROR[0m | [llm.core.llm_core:74] | Model initialization failed: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb19b-6e8f21a54f52b18345f4ed64;02ae7881-695d-4b78-96a2-5921580a1f24)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:16:24,575 | [91mERROR[0m | [llm.core.llm_core:34] | Failed to initialize LLMCore: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb19b-6e8f21a54f52b18345f4ed64;02ae7881-695d-4b78-96a2-5921580a1f24)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 30, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:16:24,578 | [91mERROR[0m | [__main__:143] | Core components initialization failed: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb19b-6e8f21a54f52b18345f4ed64;02ae7881-695d-4b78-96a2-5921580a1f24)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 138, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 30, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:16:24,580 | [95mCRITICAL[0m | [__main__:55] | Failed to initialize JARVIS: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb19b-6e8f21a54f52b18345f4ed64;02ae7881-695d-4b78-96a2-5921580a1f24)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 47, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 138, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 30, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:19:45,400 | [93mWARNING[0m | [__main__:120] | Invalid llm config, using defaults
2025-05-07 21:19:45,405 | [92mINFO[0m | [__main__:165] | System components initialized
2025-05-07 21:19:45,405 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 21:19:45,405 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: jarvis-llm
2025-05-07 21:19:45,627 | [91mERROR[0m | [llm.core.llm_core:74] | Model initialization failed: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb264-0e671fe528aced6c61747a3c;49e9230e-767f-49dd-95eb-0853f4a7e7ac)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:19:45,632 | [91mERROR[0m | [llm.core.llm_core:34] | Failed to initialize LLMCore: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb264-0e671fe528aced6c61747a3c;49e9230e-767f-49dd-95eb-0853f4a7e7ac)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 30, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:19:45,635 | [91mERROR[0m | [__main__:143] | Core components initialization failed: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb264-0e671fe528aced6c61747a3c;49e9230e-767f-49dd-95eb-0853f4a7e7ac)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 138, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 30, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:19:45,638 | [95mCRITICAL[0m | [__main__:55] | Failed to initialize JARVIS: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb264-0e671fe528aced6c61747a3c;49e9230e-767f-49dd-95eb-0853f4a7e7ac)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 47, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 138, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 30, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:43:33,250 | [93mWARNING[0m | [__main__:122] | Invalid llm config, using defaults
2025-05-07 21:43:33,256 | [92mINFO[0m | [__main__:167] | System components initialized
2025-05-07 21:43:33,257 | [92mINFO[0m | [llm.optimization.llm_optimizer:35] | Initializing LLMOptimizer with device: cpu
2025-05-07 21:43:33,257 | [92mINFO[0m | [llm.core.llm_core:64] | Loading model: jarvis-llm
2025-05-07 21:43:33,469 | [91mERROR[0m | [llm.core.llm_core:74] | Model initialization failed: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb7f8-71347e620fc013755f017744;c700c8f7-29d1-44af-bcea-308d8a257d90)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:43:33,474 | [91mERROR[0m | [llm.core.llm_core:34] | Failed to initialize LLMCore: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb7f8-71347e620fc013755f017744;c700c8f7-29d1-44af-bcea-308d8a257d90)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 30, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:43:33,477 | [91mERROR[0m | [__main__:145] | Core components initialization failed: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb7f8-71347e620fc013755f017744;c700c8f7-29d1-44af-bcea-308d8a257d90)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 140, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 30, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
2025-05-07 21:43:33,480 | [95mCRITICAL[0m | [__main__:57] | Failed to initialize JARVIS: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 409, in hf_raise_for_status
    response.raise_for_status()
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\requests\models.py", line 1024, in raise_for_status
    raise HTTPError(http_error_msg, response=self)
requests.exceptions.HTTPError: 401 Client Error: Unauthorized for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 424, in cached_files
    hf_hub_download(
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 961, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1068, in _hf_hub_download_to_cache_dir
    _raise_on_head_call_error(head_call_error, force_download, local_files_only)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1596, in _raise_on_head_call_error
    raise head_call_error
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1484, in _get_metadata_or_catch_error
    metadata = get_hf_file_metadata(
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 1401, in get_hf_file_metadata
    r = _request_wrapper(
        ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 285, in _request_wrapper
    response = _request_wrapper(
               ^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\file_download.py", line 309, in _request_wrapper
    hf_raise_for_status(response)
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\huggingface_hub\utils\_http.py", line 459, in hf_raise_for_status
    raise _format(RepositoryNotFoundError, message, response) from e
huggingface_hub.errors.RepositoryNotFoundError: 401 Client Error. (Request ID: Root=1-681bb7f8-71347e620fc013755f017744;c700c8f7-29d1-44af-bcea-308d8a257d90)

Repository Not Found for url: https://huggingface.co/jarvis-llm/resolve/main/tokenizer_config.json.
Please make sure you specified the correct `repo_id` and `repo_type`.
If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication
Invalid username or password.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\nova_industrie\jarvis\main.py", line 49, in __init__
    self._init_core_components()
  File "c:\nova_industrie\jarvis\main.py", line 140, in _init_core_components
    self.llm = LLMCore(config=llm_config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 30, in __init__
    self._initialize_model()
  File "c:\nova_industrie\jarvis\llm\core\llm_core.py", line 66, in _initialize_model
    self.tokenizer = AutoTokenizer.from_pretrained(model_name)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 946, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\models\auto\tokenization_auto.py", line 778, in get_tokenizer_config
    resolved_config_file = cached_file(
                           ^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 266, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\bruce\AppData\Roaming\Python\Python312\site-packages\transformers\utils\hub.py", line 456, in cached_files
    raise OSError(
OSError: jarvis-llm is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'
If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`
